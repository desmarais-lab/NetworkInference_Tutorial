---
title: "NetworkInference Tutorial: Persistent Policy Diffusion Ties"
author: "Fridolin Linder and Bruce Desmarais"
date: "`r Sys.Date()`"
output: rmarkdown::html_notebook
vignette: >
  %\VignetteEncoding{UTF-8}
  %\VignetteIndexEntry{NetworkInference Tutorial: Persistent Policy Diffusion Ties}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: inline
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

In this tutorial we go through some of the functionality of the `NetworkInference` package using the example application from Desmarais et al. (2015) and extending it with the recently released [State Policy Innovation and Diffusion](https://doi.org/10.7910/DVN/CVYSR7) (SPID) database. In this paper Desmarais et al. infer a latent network for policy diffusion based on adoption of policies in the US states.

`netinf` infers the optimal diffusion network from a set of *nodes* (in this case US-states) and a number of so called *cascades* (here a cascade corresponds to a policy that is adopted by at least two states). A cascade is a series of events occurring at 
a specified time. 

If you want to follow along in your own R Session, you can clone the source files from the [github repo](https://github.com/flinder/NetworkInference_Tutorial) or you can [download](https://github.com/flinder/NetworkInference_Tutorial/archive/master.zip) them. The compiled tutorial is also available to read along here: [](http://fridolin-linder.com/NetworkInference_Tutorial/index).

## Installing the package

Installing `NetworkInference`:
```{r, eval=FALSE}
install.packages('NetworkInference')
```

Some other packages required for this tutorial:
```{r, eval=FALSE}
install.packages(c('dplyr', 'igraph', 'speedglm', 'devtools'))
devtools::install_github('desmarais-lab/spid')
```

## Exploring SPID Data

The policy adoption data is available in the package:
```{r, message=FALSE}
library(NetworkInference)
data('policies')
print(ls())
```

This loads two `data.frame`-objects. `policies` contains the adoption events and `policies_metadata` contains additional information on each policy.

```{r}
policies
```

The first column (`statenam`) gives the state that adopted the `policy` in year `adopt_year`. Let's take a closer look at the data.

```{r}
head(policies_metadata)
```
The column `policy` gives the policy identifier that connects to the `policies` data. `source` is the original data source for this policy, `first_year` the first year any state adopted this policy, `last_year` the last adoption event in the data. `adopt_count` is the number of states that adopted the policy, `description` gives more information and `majortopic` is a topic coding into the policy agenda project topic categories.

Number of policies:
```{r}
nrow(policies_metadata)
```

Number of adoption events:
```{r}
nrow(policies)
```

Some example policies:
```{r}
unique(policies$policy)[100:104]
```

Not all the policy abbreviations are understandable. So let's check the metadata for more information:
```{r, message=FALSE}
library(dplyr)
filter(policies_metadata, policy %in% unique(policy)[100:104]) %>%
    select(-source)
```

## Preparing the Data for NetworkInference

Most functionality of the `NetworkInference` package is based on the `cascades` 
data format. So before starting with the analysis we have to transform our data
to such an object.

```{r}
policy_cascades <- as_cascade_long(policies, cascade_node_name = 'statenam',
                                   event_time = 'adopt_year', 
                                   cascade_id = 'policy')
```

In this case we used the function `as_cascade_long`. If your data is in wide format you can convert it using the function `as_cascade_wide`.

The `cascade` class contains the same data as the `policies` `data.frame`, just in a different format.

```{r}
print(class(policy_cascades))
length(policy_cascades)
print(names(policy_cascades))
```

The `cascade` object contains the casacde information in three elements:
* `cascade_nodes`: A list of vectors that contain the node names (states) in order of adoption.
* `cascade_times`: A list of vectors that contain the adoption times for each state in `cascade_nodes`.
* `node_names`: A list of all nodes in the system.

Let's select a subset of two cascades so we can take a closer look at the cascade object. There are a few convenience functions to manipulate the cascades (but you can also manipulate the data before converting it to the `cascade` format).

### Subsetting by Cascade
```{r}
selected_policies <- subset_cascade(cascade = policy_cascades, 
                                    selection = c('clinic_access', 'cogrowman'))
print(selected_policies)
```

### Subsetting in Time

```{r}
time_constrained <- subset_cascade_time(cascade = selected_policies, 
                                        start_time = 1990, end_time = 2000)
print(time_constrained[1:2])
```

### Removing Nodes

```{r}
less_nodes <- drop_nodes(cascades = time_constrained, 
                         nodes = c('Maryland', 'Washington'))
print(less_nodes[1:2])
```

## Inspecting Cascades

It's always good practice to visually inspect the data before working with it. 
The `NetworkInference` package provides functionality to visualize the cascade 
data. 

The function `summary.cascades()` provides quick summary statistics on the 
cascade data:

```{r}
summary(policy_cascades)
```

The first four lines provide the number of cascades, the number of nodes in the 
system, the number of nodes involved in cascades (there might be states that we 
don't have diffusion data on, but we still want them represented in the dataset)
and the possible number of edges in a potential diffusion network (a diffusion edge 
between nodes `u` and `v` only makes sense if there is at least one cascade in 
which `u` experiences an event before `v`). In this example there are 187 
policies and 50 states. Each state is involved in at least one policy cascade 
and a fully connected diffusion network would have 2450 edges. 

It also provides summary statistics on the distribution of the cascade lengths 
(number of nodes involved in each cascade) and the number of ties in the 
cascades (two nodes experiencing the same event at the same time). For our 
example, we can see that the 'smallest' policy was adopted by 10 states and the
'largest' by all 50 states. From the tie summaries we see that there is at least
one policy that was adopted by 45 states in the same year. 

The `plot()` method allows to plot cascades with varying degrees of detail. The 
argument `label_nodes` (`TRUE/FALSE`) provides node labels which require more space
but provide more detail. The argument `selection` allows to pick a subset of 
cascades to visualize in case there are too many to plot. If `label_nodes` is set 
to `FALSE` each event is depicted by a dot, which allows to visualize more cascades
simultaneously. 

Let's first look at the visualization with labels. Here we plot two cascades, 
selected by their name:
#```{r, fig.align='center', fig.width=5, fig.height=3}
```{r, fig.align='center', fig.width=9, fig.height=3}
selection <- c('guncontrol_assaultweapon_ba', 'guncontrol_licenses_dealer')
plot(policy_cascades, label_nodes = TRUE, selection = selection)
```

We can also plot more cascades with less detail:
```{r, fig.align='center', fig.width=5, fig.height=3}
selection <- c('waiting', 'threestrikes', 'unionlimits', 'smokeban', 
               'paperterror', 'miglab', 'methpre', 'lott', 'lemon', 'idtheft',
               'harass', 'hatecrime', 'equalpay')
plot(policy_cascades, label_nodes = FALSE, selection = selection)
```

This produces a ['violin plot'](https://en.wikipedia.org/wiki/Violin_plot) for each cascade with the single diffusion events overplotted as dots. As we already saw in the previous visualization, the policy data has a lot of ties (i.e. many states adopted a policy in the same year) which is indicated by the areas of higher density in the violin plot.
    

## Inferring the Latent Diffusion Network

The `netinf` algorithm is implemented in the `netinf()` function. The `netinf` inferrs edges based on a diffusion model. That is we assume a parametric model for the diffusion times between edges. Currently three different diffusion models are implemented: The exponential distribution, the rayleigh distribution and the log-normal distribution. The model can be chosen with the `trans_mod` argument (default is the exponential distribution). 

### Classic Netinf

In the original implementation the number of edges to infer had to be fixed and chosen by the researcher. If you want to run `netinf` in this classic way you can do so by specifiying all parameters and the number of edges:

```{r}
results <- netinf(policy_cascades, trans_mod = "exponential", n_edges = 100, 
                  params = 0.5, quiet = TRUE)
results
```

The exponential model has only one parameter (lambda or the rate). If there are more parameters the details section in the documentation of the `netinf` function (`?netinf`) has more detail on how to specify parameters and on the specific parametrization used by the implementation. 

`n_edges` specifies how many edges should be inferred. See @gomez2010inferring and @desmarais2015persistent for guidance on choosing this parameter if running netinf in classic mode. If the number of edges is specified manually, it has to be lower than the maximum number of possible edges. An edge `u->v` is only possible if in at least one cascade `u` experiences an event *before* `v`. This means, that the maximum number of edges depends on the data. The function `count_possible_edges()` allows us to compute the maximum number of edges in advance:
 
```{r}
npe <- count_possible_edges(policy_cascades)
npe
```


### Automatic Parameter Selection

With version 1.2.0 `netinf` can be run without manually specifying the number of edges or the parameters of the diffusion model. 

#### Selecting the number of edges automatically

After each iteration of the netinf algorithm, we check if the edge added significant improvement to the network. This is done via a vuong style test. Given the likelihood score for each cascade conditional on the network inferred so far, we penalize the network with one addional edge and test if the increase in likelihood accross all cascades is significant. The user still has to specify a p-value cut-off. If the p-value of an edge is larger than the specified cut-off the algorithm stops inferring more edges. The cut-off is set via the `p_value_cutoff` argument.

```{r}
results <- netinf(policy_cascades, trans_mod = "exponential", 
                  p_value_cutoff = 0.1, params = 0.5, quiet = TRUE)
results
```

We see that with a fixed lambda of 0.5 and a p-value cut-off of 0.1 the algorithm inferred 872 edges.

#### Selecting the parameters of the diffusion model

The diffusion model parameters can be selected automatically. Setting the `params` argument to `NULL` (default value) makes the `netinf` function initialize the parameters automatically. The parameters are initialized at the midpoint between the MLE of the minimum diffusion times and the MLE of the maximum diffusion times, across all cascades. Edges are then inferred until either the p-value cut-off or a manually specified number of edges (`n_edges`) is reached. 

```{r}
results <- netinf(policy_cascades, trans_mod = "exponential", 
                  p_value_cutoff = 0.1, quiet = TRUE)
attr(results, 'diffusion_model_parameters')
```

### Netinf output

Let's take a look at the output of the algorithm. The output is a dataframe containing the inferred latent network in the form of an edgelist:

```{r}
results
```

Each row corresponds to a directed edge. The first column indicates the origin node, the second the destination node. The third column displays the gain in model fit from each added edge. The last column displays the p-value from the Vuong test of each edge. There is a generic plot method to inspect the results. If more tweaking is required, the results are a dataframe so it should be easy for the more experienced users to make your own plot. With `type = "improvement"` the improvement from each edge can be plotted:

```{r, fig.align='center', fig.width=7, fig.height=4}
plot(results, type = "improvement")
```

We can also quickly check the p-value from the Vuong test associated with each edge addition:

```{r, fig.align='center', fig.width=7, fig.height=4}
plot(results, type = 'p-value')
```

In order to produce a quick visualization of the resulting diffusion network we can use the plot method again, this time with `type = "network"`. Note that in order to use this functionality the igraph package has to be installed.

```{r, fig.width=7, fig.height=5.5}
#install.packages('igraph')
# For this functionality the igraph package has to be installed
# This code is only executed if the package is found:
if(requireNamespace("igraph", quietly = TRUE)) {
    plot(results, type = "network")
}
```

If additional tweaking of the plot is desired, the network can be visualized using `igraph` explicitly. We refer you you to the [igraph documentation](https://CRAN.R-project.org/package=igraph) for details on how to customize the plot.

```{r, message=FALSE, eval=FALSE}
if(requireNamespace("igraph", quietly = TRUE)) {
    library(igraph) 
    g <- graph_from_data_frame(d = results[, 1:2])
    plot(g, edge.arrow.size=.3, vertex.color = "grey70")
}
```

## Selecting Parameters with Event History Analysis

We will release an R-package for policy diffusion analysis `spid`. Until then you can already use some of the functions either by downloading them directly from the github repository ()[https://github.com/desmarais-lab/spid] or by installing the (alpha version of) the package:
```{r, message=FALSE}
library(spid)
```

We want to evaluate each combination of three parameters on a grid:

* Number of edges
* Diffusion model parameters ($\lambda$)
* Size of the time window used for the inference of each network

```{r}
n_edges = c(500, 700)
lambdas = c(0.5, 1)
time_windows = c(50, 100)
param_grid = expand.grid(n_edges, lambdas, time_windows)
colnames(param_grid) = c('n_edges', 'lambdas', 'time_windows')
head(param_grid)
```

For each grid point, we need to infer a network for every year using the parameters of that grid point. For one year:
```{r, message=FALSE}
library(spid)
network = infer_network(time = 1960, time_window = time_windows[1], 
                        cascades = policy_cascades, params = lambdas[1], 
                        n_edges = n_edges[1])
head(network)
```
For all years:
```{r, cache=TRUE}
years = 1960:2015
networks = lapply(years, infer_network, time_window = time_windows[1],
                  cascades = policy_cascades, params = lambdas[1], 
                  n_edges = n_edges[1])
# Cast into single dataframe:
networks = do.call(rbind, networks)
head(networks)
```

Now we can construct the EHA data frame:
```{r, cache=TRUE}
eha_data = make_eha_data(cascades = policy_cascades, networks = networks, 
                         min_time = 1960, decay_parameter = lambdas[1])
head(eha_data)
```

With the eha dataset we can now fit the eha model:
```{r, cache=TRUE}
library(speedglm)
mod <- event ~ events_so_far + n_neighbor_events_decay + cascade_id
res <- speedglm::speedglm(mod, data = eha_data,
                          family = binomial(link = "logit"))
BIC(res)
```

The `spid` package will do all of this automatically on the whole parameter grid:
```{r, cache=TRUE}
#grid_search_results = grid_search_eha(cascades = policy_cascades, n_jobs = 4,
#                                      n_edges = n_edges, params = lambdas, 
#                                      time_windows = time_windows)
#save(grid_search_results, file = 'grid_search_results.RData')
load('grid_search_results.RData')
head(arrange(grid_search_results, bic))
```